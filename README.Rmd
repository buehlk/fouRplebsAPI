---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# fouRplebsAPI

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-stable.svg)](https://lifecycle.r-lib.org/articles/stages.html#stable) 
[![R-CMD-check](https://github.com/buehlk/fouRplebsAPI/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/buehlk/fouRplebsAPI/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

The R package fouRplebsAPI enables researchers to query the 4chan database archived by [4plebs.org](https://www.4plebs.org/). 
This database is the largest ongoing archive of the ever-disappearing posts on the imageboard 4chan. With this package researchers can use the detailed search functionalities offered by 4plebs and retrieve structured data of the communication on 4chan.

The package is based on [4plebs API documentation](https://4plebs.tech/foolfuuka/).

The 4chan boards currently covered by 4plebs are:

```{r echo = FALSE, results = 'asis', warning=FALSE}
library(knitr)
kable(data.frame("Board name" = c("Politically Incorrect", "High Resolution", "Traditional Games", "Television & Film", "Paranormal", "Sh*t 4chan Says", "Auto", "Advice", "Travel", "Flash", "Sports", "My Little Politics", "Mecha & Auto"),
                 "Abbreviation" = c("pol", "hr", "tg", "tv", "x", "s4s", "o", "adv", "trv", "f", "sp", "mlpol", "mo")
                 )
      )

```

## Installation

You can install the fouRplebsAPI from GitHub with:

``` r
# install.packages("devtools")
devtools::install_github("buehlk/fouRplebsAPI")
```

## Search the 4chan archive

While this package includes several funtions that allow researchers to query and inspect specific 4chan posts (get_4chan_post) or threads (get_4chan_thread), researchers wanting to collect data from the 4plebs archive will probably be interested in collecting a larger amount of data.

The *first* way of collecting data is by collecting the latest threads in a given board. Let's say you are interested in the 20 latest threads from the "Advice" board (excluding the comments accompanying the opening post), one way of querying the data is:

```{r example1}
library(fouRplebsAPI)

recentAdv <- get_4chan_board_range(board = "adv", page_start = 1, page_stop = 2, latest_comments = FALSE)

str(recentAdv, vec.len = 1, nchar.max = 60)
```

The output description can be found in the function documentations. Theoretically it would be possible to scrape vast ranges of the archive with this function, even though the API has an API rate limit, which slows down the querying process. 

A *second* way collecting 4chan data with this package is the search function. 4plebs allows for a very detailed search with many search filter. I will show only simple examples of the data that can be collected with fouRplebsAPI.

The example I show here is rather cheerful, because I would like to avoid the more controversial topics for which 4chan, especially the /pol/ board is notorious. Researchers, for instance the ones interested in the political communication of actors with contentious ideologies, will find it easy to adapt this example. 
But this one is about vacation.

Let's find the communication in the "Travel" board that discusses Mallorca, Spain.

First, to get a first impression of the search results, one can inspect a snippet of the 25 most recent posts containing the search term "mallorca".

```{r example2}
mallorca_snippet <- search_4chan_snippet(boards = "trv", start_date = "2021-01-01", end_date = "2022-12-31", text = "mallorca")

str(mallorca_snippet, vec.len = 1, nchar.max = 60)
```
Note that the function search_4chan_snippet() also prints the total number of search results and the estimated time to retrieve them with search_4chan(). This estimation is based on 5 requests per minute API limit.

Users only interested in the number of results can just retrieve them by changing the parameter result_type to "results_num". Now one can compare the number of posts mentioning Mallorca between different time periods. For example, pre-pandemic vs. post-pandemic:

```{r example3}
mallorca_pre <- search_4chan_snippet(boards = "trv", start_date = "2018-01-01", end_date = "2019-12-31", text = "mallorca", result_type = "results_num")
mallorca_post <- search_4chan_snippet(boards = "trv", start_date = "2020-01-01", end_date = "2021-12-31", text = "mallorca", result_type = "results_num")

data.frame("Years" = c("2018 & 2019", "2020 & 2021"),
       "Total results" = c(mallorca_pre["total_found"], mallorca_post["total_found"])
       )
```
It seems that this island has been mentioned more as people tended to stay home.

Researchers interested in gathering more data than just a snippet of the posts can use the function search_4chan(). Staying with the example of posts mentioning Mallorca over time, one could be inclined to ask, whether the image of Mallorca has changed during the pandemic. Apart from simply getting *all* the posts mentioning a search term, it is for example possible to filter for posts containing image data:

```{r example4}
mallorca_pre_pics <- search_4chan(boards = "trv", start_date = "2018-01-01", end_date = "2019-12-31", text = "mallorca", show_only = "image")
mallorca_post_pics <- search_4chan_snippet(boards = "trv", start_date = "2018-01-01", end_date = "2019-12-31", text = "mallorca", show_only = "image")

head(mallorca_post_pics$media_link)
```
The column media_link provides the downloadable image links of the posts retrieved.

